{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udcca Commercial Analytical Platform (CAP) - Complete Demo Notebook\n",
    "\n",
    "> **Interactive demonstration of Commercial Analytical Platform (CAP) package from installation to deployment**\n",
    "\n",
    "This notebook provides a complete walkthrough of Commercial Analytical Platform (CAP) capabilities including:\n",
    "- \ud83d\udce6 Local package installation and verification\n",
    "- \ud83d\udd27 Metric creation and implementation\n",
    "- \ud83e\uddea Testing with rich outputs (DataFrames, Plotly charts)\n",
    "- \ud83d\uddd1\ufe0f Metric cleanup and removal\n",
    "- \ud83d\udcca Interactive dashboard demonstration\n",
    "- \ud83c\udf10 API server usage and testing\n",
    "- \ud83d\ude80 Deployment preparation for Posit Connect\n",
    "\n",
    "## \ud83c\udfaf What You'll Learn\n",
    "\n",
    "By the end of this notebook, you'll understand how to:\n",
    "- Install and set up Commercial Analytical Platform (CAP) from source\n",
    "- Create metrics with rich outputs (DataFrames, Plotly charts, mixed objects)\n",
    "- Test metrics interactively using the built-in dashboard\n",
    "- Remove metrics and clean up files when no longer needed\n",
    "- Use the API server for production deployment\n",
    "- Prepare metrics for Posit Connect deployment\n",
    "\n",
    "## \u26a1 Quick Start Options\n",
    "\n",
    "### \ud83e\uddea **Option 1: Run This Notebook (Recommended)**\n",
    "- Follow all cells step-by-step for complete experience\n",
    "- See live metric execution and rich outputs\n",
    "- Interactive exploration of all features\n",
    "\n",
    "### \ud83d\ude80 **Option 2: Try Components Directly**\n",
    "\n",
    "```bash\n",
    "# Test installation first\n",
    "python test_installation.py\n",
    "\n",
    "# List available metrics  \n",
    "cap list\n",
    "\n",
    "# Create a new metric\n",
    "cap create \"Your Metric\" --template simple\n",
    "\n",
    "# Remove a metric\n",
    "cap remove your_metric_id\n",
    "\n",
    "# Try the interactive dashboard\n",
    "cap dashboard\n",
    "# Open: http://localhost:8050\n",
    "\n",
    "# Try the API server\n",
    "cap api  \n",
    "# Open: http://localhost:8000/docs\n",
    "```\n",
    "\n",
    "## \ud83d\udccb Notebook Contents Overview\n",
    "\n",
    "| Step | Description | Key Features |\n",
    "|------|-------------|--------------|\n",
    "| 1-2 | **Installation & Setup** | Package verification, structure exploration |\n",
    "| 3-5 | **Example Metrics** | Test built-in financial analysis with rich outputs |\n",
    "| 6-8 | **Create New Metric** | Scaffolding system, template enhancement |\n",
    "| 9 | **Metric Cleanup** | Remove command, file cleanup |\n",
    "| 10-12 | **API Integration** | FastAPI server, multiple output formats |\n",
    "| 13-14 | **Dashboard & Deployment** | Interactive testing, Posit Connect prep |\n",
    "| 15 | **Advanced Features** | Output formats, testing framework |\n",
    "\n",
    "---\n",
    "\n",
    "**\ud83c\udf89 Let's start building powerful metrics with rich outputs! \ud83c\udf89**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udce6 Step 1: Installation\n",
    "\n",
    "\u26a0\ufe0f **IMPORTANT**: The package has been **fixed and tested** to work correctly! Any previous import errors have been resolved.\n",
    "\n",
    "\u2705 **All components are working**:\n",
    "- Metric registry and discovery\n",
    "- Example financial analysis metric  \n",
    "- CLI commands (`list`, `create`, `dashboard`, `api`)\n",
    "- API server and dashboard applications\n",
    "- Rich output processing (DataFrames, Plotly charts)\n",
    "\n",
    "Let's install Commercial Analytical Platform (CAP) from the local development version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/alan/Documents/GitHub/metric\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: click>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cap==1.0.0) (8.2.1)\n",
      "Requirement already satisfied: fastapi>=0.100.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cap==1.0.0) (0.116.1)\n",
      "Requirement already satisfied: numpy>=1.24.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cap==1.0.0) (1.26.4)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cap==1.0.0) (2.2.1)\n",
      "Requirement already satisfied: plotly>=5.14.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cap==1.0.0) (6.2.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cap==1.0.0) (2.11.7)\n",
      "Requirement already satisfied: pyyaml>=6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cap==1.0.0) (6.0.1)\n",
      "Requirement already satisfied: uvicorn>=0.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cap==1.0.0) (0.35.0)\n",
      "Requirement already satisfied: black>=23.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cap==1.0.0) (25.1.0)\n",
      "Requirement already satisfied: dash>=2.14.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cap==1.0.0) (3.1.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cap==1.0.0) (5.10.4)\n",
      "Requirement already satisfied: psycopg2-binary>=2.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cap==1.0.0) (2.9.10)\n",
      "Requirement already satisfied: pytest-asyncio>=0.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cap==1.0.0) (1.1.0)\n",
      "Requirement already satisfied: pytest>=7.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cap==1.0.0) (8.4.1)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cap==1.0.0) (2.32.4)\n",
      "Requirement already satisfied: ruff>=0.0.270 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cap==1.0.0) (0.12.8)\n",
      "Requirement already satisfied: sqlalchemy>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cap==1.0.0) (2.0.41)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from black>=23.3.0->cap==1.0.0) (1.1.0)\n",
      "Requirement already satisfied: packaging>=22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from black>=23.3.0->cap==1.0.0) (25.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from black>=23.3.0->cap==1.0.0) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in /Users/alan/Library/Python/3.12/lib/python/site-packages (from black>=23.3.0->cap==1.0.0) (4.2.0)\n",
      "Requirement already satisfied: Flask<3.2,>=1.0.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dash>=2.14.0->cap==1.0.0) (3.1.1)\n",
      "Requirement already satisfied: Werkzeug<3.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dash>=2.14.0->cap==1.0.0) (3.1.3)\n",
      "Requirement already satisfied: importlib-metadata in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dash>=2.14.0->cap==1.0.0) (8.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dash>=2.14.0->cap==1.0.0) (4.14.1)\n",
      "Requirement already satisfied: retrying in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dash>=2.14.0->cap==1.0.0) (1.4.0)\n",
      "Requirement already satisfied: nest-asyncio in /Users/alan/Library/Python/3.12/lib/python/site-packages (from dash>=2.14.0->cap==1.0.0) (1.6.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dash>=2.14.0->cap==1.0.0) (80.9.0)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fastapi>=0.100.0->cap==1.0.0) (0.47.2)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbformat>=4.2.0->cap==1.0.0) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nbformat>=4.2.0->cap==1.0.0) (4.25.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/alan/Library/Python/3.12/lib/python/site-packages (from nbformat>=4.2.0->cap==1.0.0) (5.7.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in /Users/alan/Library/Python/3.12/lib/python/site-packages (from nbformat>=4.2.0->cap==1.0.0) (5.14.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=2.0.0->cap==1.0.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=2.0.0->cap==1.0.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=2.0.0->cap==1.0.0) (2024.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from plotly>=5.14.0->cap==1.0.0) (1.46.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic>=2.0.0->cap==1.0.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic>=2.0.0->cap==1.0.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic>=2.0.0->cap==1.0.0) (0.4.1)\n",
      "Requirement already satisfied: iniconfig>=1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pytest>=7.3.0->cap==1.0.0) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pytest>=7.3.0->cap==1.0.0) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in /Users/alan/Library/Python/3.12/lib/python/site-packages (from pytest>=7.3.0->cap==1.0.0) (2.17.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.31.0->cap==1.0.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.31.0->cap==1.0.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.31.0->cap==1.0.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.31.0->cap==1.0.0) (2025.7.9)\n",
      "Requirement already satisfied: h11>=0.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from uvicorn>=0.22.0->cap==1.0.0) (0.16.0)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from Flask<3.2,>=1.0.4->dash>=2.14.0->cap==1.0.0) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from Flask<3.2,>=1.0.4->dash>=2.14.0->cap==1.0.0) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from Flask<3.2,>=1.0.4->dash>=2.14.0->cap==1.0.0) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from Flask<3.2,>=1.0.4->dash>=2.14.0->cap==1.0.0) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->cap==1.0.0) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->cap==1.0.0) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->cap==1.0.0) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->cap==1.0.0) (0.26.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->cap==1.0.0) (1.16.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from starlette<0.48.0,>=0.40.0->fastapi>=0.100.0->cap==1.0.0) (4.10.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from importlib-metadata->dash>=2.14.0->cap==1.0.0) (3.23.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi>=0.100.0->cap==1.0.0) (1.3.1)\n",
      "Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: cap\n",
      "  Building editable for cap (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cap: filename=cap-1.0.0-py3-none-any.whl size=6709 sha256=820cf5fa7939ae3a866c2b07f8d738247b70898816f5c592c0c2a727730faab3\n",
      "  Stored in directory: /private/var/folders/h8/23250j7n7mq4rh4gnm_4v8d80000gn/T/pip-ephem-wheel-cache-hujj5_3t/wheels/cf/b8/eb/81ad5a6a808d174602c8f580479484c0f232b32250e62304a2\n",
      "Successfully built cap\n",
      "Installing collected packages: cap\n",
      "  Attempting uninstall: cap\n",
      "    Found existing installation: cap 1.0.0\n",
      "    Uninstalling cap-1.0.0:\n",
      "      Successfully uninstalled cap-1.0.0\n",
      "Successfully installed cap-1.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "zsh:1: 4.2.0 not found\n",
      "\ud83d\udd0d Running installation verification test...\n",
      "\ud83d\ude80 Commercial Analytical Platform (CAP) Installation Test\n",
      "========================================\n",
      "\ud83d\udd0d Testing imports...\n",
      "  \u2705 cap imported successfully (version: 1.0.0)\n",
      "  \u2705 Core functions imported\n",
      "  \u2705 API components imported\n",
      "  \u2705 Dashboard components imported\n",
      "  \u2705 Registry components imported\n",
      "\n",
      "\ud83d\udcca Testing metric registry...\n",
      "  \u2705 Registry loaded successfully\n",
      "  \ud83d\udcca Found 1 metrics:\n",
      "    \u2022 demo_simple_calculator: Demo Simple Calculator\n",
      "\n",
      "\ud83e\uddea Testing metric calculation...\n",
      "  \ud83e\uddee Testing metric: demo_simple_calculator\n",
      "  \u2705 Metric calculation successful!\n",
      "  \ud83d\udcca Result keys: ['price_data', 'performance_chart', 'correlation_heatmap', 'statistics_table', 'summary_metrics']\n",
      "    price_data: DataFrame\n",
      "    performance_chart: Figure\n",
      "    correlation_heatmap: Figure\n",
      "    statistics_table: DataFrame\n",
      "    summary_metrics: dict\n",
      "\n",
      "\ud83c\udf10 Testing API creation...\n",
      "  \u2705 API app created successfully\n",
      "\n",
      "\ud83d\udcca Testing dashboard creation...\n",
      "  \u2705 Dashboard app created successfully\n",
      "\n",
      "========================================\n",
      "\ud83d\udccb Test Summary:\n",
      "  \u2705 PASS: Imports\n",
      "  \u2705 PASS: Registry\n",
      "  \u2705 PASS: Metric Calculation\n",
      "  \u2705 PASS: API Creation\n",
      "  \u2705 PASS: Dashboard Creation\n",
      "\n",
      "\ud83c\udfaf Overall: 5/5 tests passed\n",
      "\n",
      "\ud83c\udf89 All tests passed! Commercial Analytical Platform (CAP) is ready to use.\n",
      "\n",
      "\ud83d\ude80 Next steps:\n",
      "  1. Run: python -c \"from cap.scaffolding.cli import cli; cli()\" list\n",
      "  2. Run: python -c \"from cap.scaffolding.cli import cli; cli()\" dashboard\n",
      "  3. Try the Jupyter notebook: CAP_Demo.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Install the package from local directory\n",
    "# Run this from the root directory containing pyproject.toml\n",
    "!pip3 install -e \".[all]\"\n",
    "\n",
    "# Install additional Jupyter dependencies for Plotly visualization\n",
    "!pip3 install nbformat>=4.2.0 ipywidgets\n",
    "\n",
    "# \ud83e\uddea IMPORTANT: Test installation first!\n",
    "# The test_installation.py script verifies that everything works correctly\n",
    "print(\"\ud83d\udd0d Running installation verification test...\")\n",
    "!python3 test_installation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83e\uddea About the Installation Test Script\n",
    "\n",
    "### \ud83c\udfaf Purpose of `test_installation.py`\n",
    "\n",
    "The `test_installation.py` script is a **comprehensive verification tool** that ensures all Commercial Analytical Platform (CAP) components are working correctly after installation. Here's what it does:\n",
    "\n",
    "#### \u2705 **5 Critical Tests**:\n",
    "\n",
    "1. **\ud83d\udd0d Import Test**: Verifies all Python modules can be imported correctly\n",
    "   - Tests core functions (`register_metric`, `call_metric`, etc.)\n",
    "   - Tests API components (`create_api_app`)\n",
    "   - Tests dashboard components (`create_dashboard_app`)\n",
    "   - Tests registry system (`get_registry`)\n",
    "\n",
    "2. **\ud83d\udcca Registry Test**: Ensures the metric discovery system works\n",
    "   - Loads the metric registry\n",
    "   - Discovers available metrics\n",
    "   - Validates metric configurations\n",
    "\n",
    "3. **\ud83e\uddee Calculation Test**: Verifies metrics can actually run\n",
    "   - Calls the example financial analysis metric\n",
    "   - Tests with real parameters\n",
    "   - Validates rich output types (DataFrames, Plotly charts)\n",
    "\n",
    "4. **\ud83c\udf10 API Test**: Confirms the FastAPI server can be created\n",
    "   - Creates the API application\n",
    "   - Ensures all endpoints are available\n",
    "\n",
    "5. **\ud83d\udcca Dashboard Test**: Validates the Dash dashboard works\n",
    "   - Creates the dashboard application\n",
    "   - Ensures interactive components are ready\n",
    "\n",
    "#### \ud83d\udea8 **Why This Matters**:\n",
    "\n",
    "- **Early Problem Detection**: Catches issues before you start the demo\n",
    "- **Environment Validation**: Ensures your Python environment is compatible\n",
    "- **Dependency Verification**: Confirms all required packages are installed\n",
    "- **Quick Diagnostics**: Provides clear pass/fail results with error details\n",
    "\n",
    "#### \ud83d\udd27 **When to Use**:\n",
    "\n",
    "- **After installation**: Always run this first\n",
    "- **Before demos**: Ensure everything works before presenting\n",
    "- **Troubleshooting**: When things aren't working as expected\n",
    "- **Environment changes**: After updating Python or dependencies\n",
    "\n",
    "The script gives you **confidence** that Commercial Analytical Platform (CAP) is ready to use! \ud83c\udf89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core components\n",
    "import cap\n",
    "from cap import register_metric, get_metric, list_metrics, call_metric\n",
    "from cap.api import create_api_app\n",
    "from cap.dashboard import create_dashboard_app\n",
    "\n",
    "# Check package info\n",
    "print(f\"\ud83d\udce6 Package Version: {cap.__version__}\")\n",
    "print(f\"\ud83d\udccd Package Location: {cap.__file__}\")\n",
    "print(f\"\ud83d\udd27 Available Functions: {cap.__all__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcc8 Step 3: Test Existing Example Metric\n",
    "\n",
    "Let's test the example financial analysis metric that comes with the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available metrics\n",
    "available_metrics = list_metrics()\n",
    "print(f\"\ud83d\udcca Available Metrics ({len(available_metrics)}):\")\n",
    "for metric in available_metrics:\n",
    "    print(f\"  \u2022 {metric['id']}: {metric.get('name', 'No name')}\")\n",
    "    print(f\"    Category: {metric.get('category', 'Unknown')}\")\n",
    "    print(f\"    Description: {metric.get('description', 'No description')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the example financial analysis metric\n",
    "if available_metrics:\n",
    "    # Use the first available metric (should be demo_simple_calculator)\n",
    "    metric_id = available_metrics[0]['id']\n",
    "    print(f\"\ud83e\uddea Testing metric: {metric_id}\")\n",
    "    \n",
    "    # Call the metric with default parameters\n",
    "    result = call_metric(metric_id, num_assets=3, time_periods=50, volatility=0.15)\n",
    "    \n",
    "    print(f\"\u2705 Metric calculation successful!\")\n",
    "    print(f\"\ud83d\udcca Result keys: {list(result.keys())}\")\n",
    "    \n",
    "    # Display each output type\n",
    "    for key, value in result.items():\n",
    "        print(f\"\\n\ud83d\udd0d {key}: {type(value).__name__}\")\n",
    "        if hasattr(value, 'shape'):\n",
    "            print(f\"  Shape: {value.shape}\")\n",
    "        elif hasattr(value, '__len__') and not isinstance(value, str):\n",
    "            print(f\"  Length: {len(value)}\")\n",
    "else:\n",
    "    print(\"\u274c No metrics found. Let's create one!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Step 4: Explore Rich Outputs\n",
    "\n",
    "Let's examine the different types of rich outputs that Commercial Analytical Platform (CAP) supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we have results, let's explore them\n",
    "if 'result' in locals() and result:\n",
    "    \n",
    "    # 1. DataFrame Output\n",
    "    if 'price_data' in result:\n",
    "        print(\"\ud83d\udcca DATAFRAME OUTPUT:\")\n",
    "        price_df = result['price_data']\n",
    "        print(f\"Shape: {price_df.shape}\")\n",
    "        print(\"\\nFirst 5 rows:\")\n",
    "        display(price_df.head())\n",
    "        \n",
    "        print(\"\\nData types:\")\n",
    "        print(price_df.dtypes)\n",
    "    \n",
    "    # 2. Summary Statistics\n",
    "    if 'summary_metrics' in result:\n",
    "        print(\"\\n\ud83d\udccb SUMMARY METRICS:\")\n",
    "        import json\n",
    "        print(json.dumps(result['summary_metrics'], indent=2))\n",
    "    \n",
    "    # 3. Statistics Table\n",
    "    if 'statistics_table' in result:\n",
    "        print(\"\\n\ud83d\udcc8 STATISTICS TABLE:\")\n",
    "        display(result['statistics_table'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcc8 Step 5: Display Interactive Visualizations\n",
    "\n",
    "Let's display the Plotly charts generated by our metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Plotly charts if available\n",
    "if 'result' in locals() and result:\n",
    "    \n",
    "    # Performance Chart\n",
    "    if 'performance_chart' in result:\n",
    "        print(\"\ud83d\udcc8 INTERACTIVE PERFORMANCE CHART:\")\n",
    "        try:\n",
    "            result['performance_chart'].show()\n",
    "        except ValueError as e:\n",
    "            if \"nbformat\" in str(e):\n",
    "                print(\"\u26a0\ufe0f  Plotly display requires nbformat. Install with: pip install nbformat>=4.2.0\")\n",
    "                print(\"\ud83d\udcca Chart created successfully (would display in proper Jupyter environment)\")\n",
    "                print(f\"\ud83d\udccf Chart data shape: {len(result['performance_chart'].data)} traces\")\n",
    "            else:\n",
    "                print(f\"\u274c Error displaying chart: {e}\")\n",
    "    \n",
    "    # Correlation Heatmap\n",
    "    if 'correlation_heatmap' in result:\n",
    "        print(\"\\n\ud83c\udfaf CORRELATION HEATMAP:\")\n",
    "        try:\n",
    "            result['correlation_heatmap'].show()\n",
    "        except ValueError as e:\n",
    "            if \"nbformat\" in str(e):\n",
    "                print(\"\u26a0\ufe0f  Plotly display requires nbformat. Install with: pip install nbformat>=4.2.0\")\n",
    "                print(\"\ud83d\udcca Heatmap created successfully (would display in proper Jupyter environment)\")\n",
    "                print(f\"\ud83d\udccf Heatmap data shape: {len(result['correlation_heatmap'].data)} traces\")\n",
    "            else:\n",
    "                print(f\"\u274c Error displaying heatmap: {e}\")\n",
    "else:\n",
    "    print(\"\u274c No results available. Run the previous cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udee0\ufe0f Step 6: Create a New Metric\n",
    "\n",
    "Now let's create a new metric to demonstrate the scaffolding system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new metric using the CLI\n",
    "!cap create \"Simple Calculator\" \\\n",
    "    --category demo \\\n",
    "    --description \"Simple mathematical calculations with visualization\" \\\n",
    "    --template simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcdd Step 7: Implement the New Metric\n",
    "\n",
    "Let's examine and then implement our newly created metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what files were created\n",
    "!ls -la cap/metrics/demo_simple_calculator.*\n",
    "!ls -la tests/test_demo_simple_calculator.py\n",
    "!ls -la deploy_demo_simple_calculator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the generated metric file\n",
    "with open('cap/metrics/demo_simple_calculator.py', 'r') as f:\n",
    "    print(\"\ud83d\udcc4 Generated Metric Code:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a more interesting implementation\n",
    "enhanced_metric_code = '''\n",
    "\"\"\"\n",
    "Simple Calculator Metric with Rich Outputs\n",
    "\n",
    "Demonstrates basic mathematical operations with visualization.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from cap import register_metric\n",
    "from typing import Dict, Any, Sequence\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "@register_metric(\"demo_simple_calculator\")\n",
    "def calculate_simple_calculator(\n",
    "    input_data: Sequence[float],\n",
    "    operation: str = \"all\"\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Simple mathematical calculations with rich outputs.\n",
    "    \n",
    "    Args:\n",
    "        input_data: Primary numeric sequence supplied to the calculator metric\n",
    "        operation: Type of operation (\"all\", \"sum\", \"mean\", \"std\")\n",
    "    \n",
    "    Returns:\n",
    "        Dict with calculations table, visualization, and summary\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if input_data is None:\n",
    "            raise ValueError(\"input_data is required\")\n",
    "\n",
    "        try:\n",
    "            sequence = list(input_data)\n",
    "        except TypeError as exc:\n",
    "            raise ValueError(\"input_data must be an iterable of numeric values\") from exc\n",
    "\n",
    "        logger.info(\"Calculating with input_data: %s, operation: %s\", sequence, operation)\n",
    "\n",
    "        # Input validation\n",
    "        if not sequence:\n",
    "            raise ValueError(\"Input sequence cannot be empty\")\n",
    "\n",
    "        # Ensure all entries are numeric\n",
    "        try:\n",
    "            arr = np.array([float(x) for x in sequence], dtype=float)\n",
    "        except (TypeError, ValueError) as exc:\n",
    "            raise ValueError(\"All input values must be numeric\") from exc\n",
    "        \n",
    "        # --- CAP USER CODE START ---\n",
    "        # Perform calculations\n",
    "        calculations = {\n",
    "            \"sum\": float(np.sum(arr)),\n",
    "            \"mean\": float(np.mean(arr)),\n",
    "            \"median\": float(np.median(arr)),\n",
    "            \"std\": float(np.std(arr)),\n",
    "            \"min\": float(np.min(arr)),\n",
    "            \"max\": float(np.max(arr)),\n",
    "            \"count\": len(arr),\n",
    "        }\n",
    "\n",
    "        # Create results DataFrame\n",
    "        results_df = pd.DataFrame(\n",
    "            {\n",
    "                \"Index\": range(len(arr)),\n",
    "                \"Value\": arr,\n",
    "                \"Squared\": arr**2,\n",
    "                \"Cumulative_Sum\": np.cumsum(arr),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Create visualization\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Add original values\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=results_df[\"Index\"],\n",
    "                y=results_df[\"Value\"],\n",
    "                mode=\"lines+markers\",\n",
    "                name=\"Original Values\",\n",
    "                line=dict(color=\"blue\", width=3),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Add mean line\n",
    "        fig.add_hline(\n",
    "            y=calculations[\"mean\"],\n",
    "            line_dash=\"dash\",\n",
    "            line_color=\"red\",\n",
    "            annotation_text=f\"Mean: {calculations['mean']:.2f}\",\n",
    "        )\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=\"Number Sequence Analysis\",\n",
    "            xaxis_title=\"Index\",\n",
    "            yaxis_title=\"Value\",\n",
    "            template=\"plotly_white\",\n",
    "            height=400,\n",
    "        )\n",
    "\n",
    "        # Create summary based on operation\n",
    "        allowed_operations = [*sorted(calculations.keys()), \"all\"]\n",
    "        if operation == \"all\":\n",
    "            summary = calculations\n",
    "        elif operation in calculations:\n",
    "            summary = {operation: calculations[operation]}\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Unsupported operation '{operation}'. Choose from {', '.join(allowed_operations)}\"\n",
    "            )\n",
    "\n",
    "        result = {\n",
    "            \"calculations_table\": results_df,\n",
    "            \"visualization\": fig,\n",
    "            \"summary_stats\": summary,\n",
    "        }\n",
    "        # --- CAP USER CODE END ---\n",
    "\n",
    "        logger.info(\"Calculation completed successfully\")\n",
    "        return result\n",
    "        \n",
    "    except ValueError as e:\n",
    "        logger.error(f\"Calculation failed: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Calculation failed: {e}\")\n",
    "        raise RuntimeError(f\"Calculator metric failed: {e}\") from e\n",
    "'''\n",
    "\n",
    "# Write the enhanced metric code\n",
    "with open('cap/metrics/demo_simple_calculator.py', 'w') as f:\n",
    "    f.write(enhanced_metric_code)\n",
    "\n",
    "print(\"\u2705 Enhanced metric implementation written!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83e\uddea Step 8: Test the New Metric\n",
    "\n",
    "Let's reload the metrics and test our new implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart the kernel or reimport to pick up changes\n",
    "import importlib\n",
    "import cap.core\n",
    "importlib.reload(cap.core)\n",
    "\n",
    "# Force reload the registry\n",
    "from cap.core import get_registry\n",
    "registry = get_registry()\n",
    "registry.load_metrics()  # Reload metrics\n",
    "\n",
    "# List metrics again\n",
    "updated_metrics = list_metrics()\n",
    "print(f\"\ud83d\udcca Updated Metrics ({len(updated_metrics)}):\")\n",
    "for metric in updated_metrics:\n",
    "    print(f\"  \u2022 {metric['id']}: {metric.get('name', 'No name')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test our new calculator metric\n",
    "try:\n",
    "    calc_result = call_metric(\n",
    "        \"demo_simple_calculator\",\n",
    "        input_data=[10, 20, 15, 25, 30, 18, 22],\n",
    "        operation=\"all\"\n",
    "    )\n",
    "    \n",
    "    print(\"\u2705 Calculator metric test successful!\")\n",
    "    print(f\"\ud83d\udcca Result keys: {list(calc_result.keys())}\")\n",
    "    \n",
    "    # Display results\n",
    "    if 'calculations_table' in calc_result:\n",
    "        print(\"\\n\ud83d\udcca Calculations Table:\")\n",
    "        display(calc_result['calculations_table'])\n",
    "    \n",
    "    if 'summary_stats' in calc_result:\n",
    "        print(\"\\n\ud83d\udccb Summary Statistics:\")\n",
    "        import json\n",
    "        print(json.dumps(calc_result['summary_stats'], indent=2))\n",
    "    \n",
    "    if 'visualization' in calc_result:\n",
    "        print(\"\\n\ud83d\udcc8 Visualization:\")\n",
    "        calc_result['visualization'].show()\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\u274c Error testing calculator metric: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\uddd1\ufe0f Step 9: Metric Cleanup and Removal\n",
    "\n",
    "Commercial Analytical Platform (CAP) includes a convenient cleanup function to remove metrics and all their related files when they're no longer needed.\n",
    "\n",
    "### \ud83c\udfaf Remove Command Features\n",
    "\n",
    "The `cap remove` command cleans up all files associated with a metric:\n",
    "- \u2705 **Python implementation** (`cap/metrics/{metric_id}.py`)\n",
    "- \u2705 **YAML configuration** (`cap/metrics/{metric_id}.yaml`) \n",
    "- \u2705 **Test file** (`tests/test_{metric_id}.py`)\n",
    "- \u2705 **Deployment script** (`deploy_{metric_id}.py`)\n",
    "- \u2705 **Requirements file** (if exists)\n",
    "\n",
    "### \ud83d\udccb Safety Features\n",
    "\n",
    "- **Existence check**: Verifies metric exists before removal\n",
    "- **File listing**: Shows exactly what will be removed\n",
    "- **Confirmation prompt**: Requires user confirmation (unless `--force` used)\n",
    "- **Error handling**: Reports any files that couldn't be removed\n",
    "- **Summary report**: Shows removal results\n",
    "\n",
    "### \ud83d\udd27 Command Usage\n",
    "\n",
    "```bash\n",
    "# Remove a metric (with confirmation)\n",
    "cap remove metric_id\n",
    "\n",
    "# Remove a metric without confirmation\n",
    "cap remove metric_id --force\n",
    "\n",
    "# See help\n",
    "cap remove --help\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's create a temporary test metric to demonstrate removal\n",
    "print(\"\ud83d\udee0\ufe0f Creating a temporary metric for removal demonstration...\")\n",
    "\n",
    "!cap create \"Temp Test Metric\" \\\n",
    "    --category temp \\\n",
    "    --description \"Temporary metric for removal demo\" \\\n",
    "    --template simple\n",
    "\n",
    "print(\"\\n\ud83d\udccb Let's see what files were created:\")\n",
    "!ls -la cap/metrics/temp_temp_test_metric.*\n",
    "!ls -la tests/test_temp_temp_test_metric.py 2>/dev/null || echo \"Test file: Not found\"\n",
    "!ls -la deploy_temp_temp_test_metric.py 2>/dev/null || echo \"Deploy file: Not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's demonstrate the remove command\n",
    "print(\"\ud83d\uddd1\ufe0f Demonstrating metric removal...\")\n",
    "\n",
    "# First, let's see the help for the remove command\n",
    "print(\"\ud83d\udcd6 Remove command help:\")\n",
    "!cap remove --help\n",
    "\n",
    "print(\"\\n\ud83d\udcca Current metrics before removal:\")\n",
    "!cap list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the temporary metric using --force to skip confirmation in the notebook\n",
    "print(\"\ud83d\uddd1\ufe0f Removing the temporary metric...\")\n",
    "\n",
    "!cap remove temp_temp_test_metric --force\n",
    "\n",
    "print(\"\\n\ud83d\udcca Verify the metric was removed:\")\n",
    "!cap list\n",
    "\n",
    "print(\"\\n\ud83d\udccb Check if files were actually removed:\")\n",
    "!ls -la cap/metrics/temp_temp_test_metric.* 2>/dev/null || echo \"\u2705 Metric files removed\"\n",
    "!ls -la tests/test_temp_temp_test_metric.py 2>/dev/null || echo \"\u2705 Test file removed\"  \n",
    "!ls -la deploy_temp_temp_test_metric.py 2>/dev/null || echo \"\u2705 Deploy file removed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udf10 Step 10: API Server Demo\n",
    "\n",
    "Let's demonstrate the FastAPI server capabilities (this will run in the background)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create the FastAPI app and ensure metrics are loaded\nfrom cap.api import create_api_app\nimport uvicorn\nimport threading\nimport time\nimport requests\n\n# Force reload metrics to ensure demo_simple_calculator is available\nimport importlib\nimport cap.core\ntry:\n    import cap.metrics.demo_simple_calculator  # Import the calculator metric\nexcept ImportError:\n    print(\"\u26a0\ufe0f  demo_simple_calculator not found, creating it...\")\n    !cap create \"Simple Calculator\" --category demo --description \"Simple mathematical calculations\" --template simple\n\n# Reload the core module and registry\nimportlib.reload(cap.core)\nfrom cap.core import get_registry\nregistry = get_registry()\nregistry.load_metrics()\n\n# Verify metrics are available\nfrom cap import list_metrics\navailable_metrics = list_metrics()\nprint(f\"\ud83d\udcca Available metrics for API testing: {[m['id'] for m in available_metrics]}\")\n\n# Create the FastAPI app\napp = create_api_app()\n\n# Function to run the server in background\ndef run_server():\n    uvicorn.run(app, host=\"127.0.0.1\", port=8000, log_level=\"warning\")\n\n# Start server in background thread\nserver_thread = threading.Thread(target=run_server, daemon=True)\nserver_thread.start()\n\n# Wait for server to start\nprint(\"\ud83d\ude80 Starting API server...\")\ntime.sleep(3)\n\n# Test the server\ntry:\n    response = requests.get(\"http://localhost:8000/\")\n    print(f\"\u2705 API Server is running! Status: {response.status_code}\")\n    print(f\"\ud83d\udcca Response: {response.json()}\")\nexcept Exception as e:\n    print(f\"\u274c Server not responding: {e}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test API endpoints\n",
    "base_url = \"http://localhost:8000\"\n",
    "\n",
    "try:\n",
    "    # List metrics via API\n",
    "    print(\"\ud83d\udccb Testing /metrics endpoint:\")\n",
    "    metrics_response = requests.get(f\"{base_url}/metrics\")\n",
    "    if metrics_response.status_code == 200:\n",
    "        api_metrics = metrics_response.json()\n",
    "        print(f\"Found {len(api_metrics)} metrics via API\")\n",
    "        metric_ids = [metric['id'] for metric in api_metrics]\n",
    "        for metric in api_metrics:\n",
    "            print(f\"  \u2022 {metric['id']}\")\n",
    "    else:\n",
    "        print(f\"\u274c Metrics endpoint failed with status: {metrics_response.status_code}\")\n",
    "        metric_ids = []\n",
    "    \n",
    "    # Test metric calculation via API (only if metric exists)\n",
    "    if \"demo_simple_calculator\" in metric_ids:\n",
    "        print(\"\\n\ud83e\uddee Testing metric calculation via API:\")\n",
    "        calc_payload = {\n",
    "            \"metric_id\": \"demo_simple_calculator\",\n",
    "            \"inputs\": {\n",
    "                \"input_data\": [5, 10, 15, 20],\n",
    "                \"operation\": \"all\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        calc_response = requests.post(f\"{base_url}/calculate\", json=calc_payload)\n",
    "        if calc_response.status_code == 200:\n",
    "            api_result = calc_response.json()\n",
    "            print(f\"\u2705 Calculation successful!\")\n",
    "            print(f\"\ud83d\udcca Result type: {api_result.get('result_type', 'unknown')}\")\n",
    "            print(f\"\ud83d\udcca Success: {api_result.get('success', False)}\")\n",
    "            \n",
    "            # Show summary stats from API result (safer handling)\n",
    "            if 'result' in api_result and api_result['result'] and 'summary_stats' in api_result['result']:\n",
    "                print(\"\\n\ud83d\udccb Summary from API:\")\n",
    "                import json\n",
    "                print(json.dumps(api_result['result']['summary_stats'], indent=2))\n",
    "        else:\n",
    "            print(f\"\u274c API calculation failed with status: {calc_response.status_code}\")\n",
    "            print(f\"Response: {calc_response.text}\")\n",
    "    else:\n",
    "        print(\"\\n\u26a0\ufe0f  demo_simple_calculator metric not found, skipping calculation test\")\n",
    "        print(\"Available metrics:\", metric_ids)\n",
    "    \n",
    "    # Test HTML endpoint (use first available metric)\n",
    "    if metric_ids:\n",
    "        test_metric = \"demo_simple_calculator\" if \"demo_simple_calculator\" in metric_ids else metric_ids[0]\n",
    "        print(f\"\\n\ud83c\udf10 Testing HTML endpoint with metric '{test_metric}':\")\n",
    "        \n",
    "        if test_metric == \"demo_simple_calculator\":\n",
    "            html_url = f\"{base_url}/calculate/demo_simple_calculator/html?input_data=[1,2,3,4,5]&operation=all\"\n",
    "        else:\n",
    "            # Use default parameters for other metrics\n",
    "            html_url = f\"{base_url}/calculate/{test_metric}/html?num_assets=2&time_periods=10\"\n",
    "        \n",
    "        html_response = requests.get(html_url)\n",
    "        if html_response.status_code == 200:\n",
    "            response_text = html_response.text if hasattr(html_response, 'text') and html_response.text else \"\"\n",
    "            print(f\"\u2705 HTML endpoint working! Content length: {len(response_text)}\")\n",
    "            print(f\"\ud83c\udf10 URL: {html_url}\")\n",
    "            print(\"   (You can open this URL in a browser to see the full HTML report)\")\n",
    "        else:\n",
    "            print(f\"\u274c HTML endpoint failed with status: {html_response.status_code}\")\n",
    "            print(f\"Response: {html_response.text[:200]}\")\n",
    "    else:\n",
    "        print(\"\\n\u26a0\ufe0f  No metrics available for HTML testing\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\u274c API testing failed: {e}\")\n",
    "    import traceback\n",
    "    print(\"Full error details:\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Step 11: Dashboard Demo Setup\n",
    "\n",
    "Now let's set up the Dash dashboard. Note: The dashboard will run in a separate process and open in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcca Dashboard app created successfully!\n",
      "\n",
      "\ud83c\udfaf Dashboard Features:\n",
      "  \u2022 Dynamic form generation based on metric inputs\n",
      "  \u2022 Real-time metric calculation\n",
      "  \u2022 Rich output display (tables, charts, statistics)\n",
      "  \u2022 Interactive Plotly visualizations\n",
      "  \u2022 Error handling and debugging\n",
      "\n",
      "\ud83d\udcdd To run the dashboard:\n",
      "1. In a terminal, navigate to this directory\n",
      "2. Run: cap dashboard\n",
      "3. Open http://localhost:8050 in your browser\n",
      "\n",
      "Or run the cell below to start it programmatically.\n"
     ]
    }
   ],
   "source": [
    "# Create dashboard app\n",
    "from cap.dashboard import create_dashboard_app\n",
    "import webbrowser\n",
    "from multiprocessing import Process\n",
    "import os\n",
    "\n",
    "# Create the dashboard app\n",
    "dashboard_app = create_dashboard_app()\n",
    "\n",
    "print(\"\ud83d\udcca Dashboard app created successfully!\")\n",
    "print(\"\\n\ud83c\udfaf Dashboard Features:\")\n",
    "print(\"  \u2022 Dynamic form generation based on metric inputs\")\n",
    "print(\"  \u2022 Real-time metric calculation\")\n",
    "print(\"  \u2022 Rich output display (tables, charts, statistics)\")\n",
    "print(\"  \u2022 Interactive Plotly visualizations\")\n",
    "print(\"  \u2022 Error handling and debugging\")\n",
    "\n",
    "print(\"\\n\ud83d\udcdd To run the dashboard:\")\n",
    "print(\"1. In a terminal, navigate to this directory\")\n",
    "print(\"2. Run: cap dashboard\")\n",
    "print(\"3. Open http://localhost:8050 in your browser\")\n",
    "print(\"\\nOr run the cell below to start it programmatically.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udcca Dashboard demo function ready.\n",
      "\ud83d\udca1 Uncomment the last line in run_dashboard_demo() to start the dashboard.\n",
      "\u26a0\ufe0f  Note: Running the dashboard will block this notebook until stopped.\n",
      "\n",
      "\ud83c\udfaf RECOMMENDED: Run dashboard in terminal for best experience:\n",
      "   1. Open a new terminal\n",
      "   2. Navigate to this project directory\n",
      "   3. Run: cap dashboard\n",
      "   4. Open http://localhost:8050 in your browser\n"
     ]
    }
   ],
   "source": [
    "# Function to run dashboard (uncomment to run)\n",
    "# WARNING: This will start a dashboard server that runs until the kernel is restarted\n",
    "\n",
    "def run_dashboard_demo():\n",
    "    \"\"\"Run dashboard in demo mode.\"\"\"\n",
    "    from cap.dashboard import run_dashboard\n",
    "    print(\"\ud83d\ude80 Starting Commercial Analytical Platform (CAP) Dashboard...\")\n",
    "    print(\"\ud83c\udf10 URL: http://localhost:8050\")\n",
    "    print(\"\\n\ud83d\udcca In the dashboard, you can:\")\n",
    "    print(\"  1. Select a metric from the dropdown\")\n",
    "    print(\"  2. Fill in the input parameters\")\n",
    "    print(\"  3. Click 'Calculate' to see results\")\n",
    "    print(\"  4. View tables, charts, and statistics\")\n",
    "    print(\"\\n\u26a0\ufe0f  To stop the dashboard, interrupt the kernel\")\n",
    "    \n",
    "    # Uncomment the next line to actually run the dashboard\n",
    "    # run_dashboard(host=\"127.0.0.1\", port=8050, debug=True)\n",
    "\n",
    "print(\"\ud83d\udcca Dashboard demo function ready.\")\n",
    "print(\"\ud83d\udca1 Uncomment the last line in run_dashboard_demo() to start the dashboard.\")\n",
    "print(\"\u26a0\ufe0f  Note: Running the dashboard will block this notebook until stopped.\")\n",
    "\n",
    "# Show instructions instead of running\n",
    "print(\"\\n\ud83c\udfaf RECOMMENDED: Run dashboard in terminal for best experience:\")\n",
    "print(\"   1. Open a new terminal\")\n",
    "print(\"   2. Navigate to this project directory\")\n",
    "print(\"   3. Run: cap dashboard\")\n",
    "print(\"   4. Open http://localhost:8050 in your browser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\ude80 Step 12: Deployment Preparation\n",
    "\n",
    "Let's examine the deployment script that was generated for Posit Connect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the deployment script\n",
    "deploy_file = 'deploy_demo_simple_calculator.py'\n",
    "if os.path.exists(deploy_file):\n",
    "    with open(deploy_file, 'r') as f:\n",
    "        deploy_content = f.read()\n",
    "    \n",
    "    print(\"\ud83d\udcc4 Generated Deployment Script:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(deploy_content)\n",
    "else:\n",
    "    print(f\"\u274c Deployment file {deploy_file} not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the deployment script locally\n",
    "print(\"\ud83e\uddea Testing deployment script locally...\")\n",
    "print(\"\\n\ud83d\udcdd In production, you would:\")\n",
    "print(\"1. Test locally: python deploy_demo_simple_calculator.py\")\n",
    "print(\"2. Deploy to Posit Connect:\")\n",
    "print(\"   rsconnect deploy fastapi deploy_demo_simple_calculator.py \\\\\")\n",
    "print(\"       --account myaccount \\\\\")\n",
    "print(\"       --title 'Simple Calculator API'\")\n",
    "\n",
    "print(\"\\n\ud83c\udf10 Deployed endpoints would include:\")\n",
    "print(\"  \u2022 /metrics - List all metrics\")\n",
    "print(\"  \u2022 /calculate - JSON calculation\")\n",
    "print(\"  \u2022 /calculate/demo_simple_calculator/html - HTML report\")\n",
    "print(\"  \u2022 /calculate/demo_simple_calculator/csv - CSV download\")\n",
    "print(\"  \u2022 /docs - Interactive API documentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udccb Step 13: Testing Framework Demo\n",
    "\n",
    "Let's run the generated tests to ensure everything works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the generated tests\n",
    "test_file = 'tests/test_demo_simple_calculator.py'\n",
    "if os.path.exists(test_file):\n",
    "    print(\"\ud83e\uddea Running generated tests...\")\n",
    "    !python -m pytest {test_file} -v\n",
    "else:\n",
    "    print(f\"\u274c Test file {test_file} not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Step 14: Output Format Demonstrations\n",
    "\n",
    "Let's demonstrate the different output formats supported by Commercial Analytical Platform (CAP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate API output formats\n",
    "from cap.api import _process_result\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Sample data\n",
    "sample_df = pd.DataFrame({\n",
    "    'Product': ['A', 'B', 'C'],\n",
    "    'Sales': [100, 150, 120],\n",
    "    'Profit': [20, 35, 25]\n",
    "})\n",
    "\n",
    "sample_chart = go.Figure(data=[\n",
    "    go.Bar(x=sample_df['Product'], y=sample_df['Sales'], name='Sales')\n",
    "])\n",
    "sample_chart.update_layout(title='Sample Sales Chart')\n",
    "\n",
    "# Test different output formats\n",
    "print(\"\ud83d\udcca DATAFRAME OUTPUT FORMATS:\")\n",
    "print(\"\\n1. JSON format:\")\n",
    "result_type, processed = _process_result(sample_df, \"json\")\n",
    "print(f\"Type: {result_type}\")\n",
    "print(f\"Data: {processed[:200]}...\" if len(str(processed)) > 200 else f\"Data: {processed}\")\n",
    "\n",
    "print(\"\\n2. HTML format:\")\n",
    "result_type, processed = _process_result(sample_df, \"html\")\n",
    "print(f\"Type: {result_type}\")\n",
    "print(f\"HTML length: {len(processed)} characters\")\n",
    "\n",
    "print(\"\\n3. CSV format:\")\n",
    "result_type, processed = _process_result(sample_df, \"csv\")\n",
    "print(f\"Type: {result_type}\")\n",
    "print(f\"CSV data:\\n{processed}\")\n",
    "\n",
    "print(\"\\n\ud83d\udcc8 PLOTLY OUTPUT FORMATS:\")\n",
    "print(\"\\n1. JSON format:\")\n",
    "result_type, processed = _process_result(sample_chart, \"json\")\n",
    "print(f\"Type: {result_type}\")\n",
    "print(f\"Keys: {list(processed.keys()) if isinstance(processed, dict) else 'Not a dict'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Step 15: Summary and Next Steps\n",
    "\n",
    "Congratulations! You've completed the full Commercial Analytical Platform (CAP) demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\ud83c\udf89 METRICS HUB DEMO COMPLETE!\\n\")\n",
    "\n",
    "print(\"\u2705 What we accomplished:\")\n",
    "print(\"  \ud83d\udce6 Installed Commercial Analytical Platform (CAP) from local source\")\n",
    "print(\"  \ud83d\udd0d Explored existing example metrics\")\n",
    "print(\"  \ud83d\udee0\ufe0f Created a new metric with scaffolding\")\n",
    "print(\"  \ud83d\udcca Implemented rich outputs (DataFrames, Plotly charts)\")\n",
    "print(\"  \ud83e\uddea Tested metrics with various input parameters\")\n",
    "print(\"  \ud83d\uddd1\ufe0f Demonstrated metric removal and cleanup\")\n",
    "print(\"  \ud83c\udf10 Demonstrated API server capabilities\")\n",
    "print(\"  \ud83d\udcca Set up interactive dashboard\")\n",
    "print(\"  \ud83d\ude80 Prepared deployment for Posit Connect\")\n",
    "print(\"  \ud83e\uddea Ran automated tests\")\n",
    "print(\"  \ud83c\udfa8 Explored multiple output formats\")\n",
    "\n",
    "print(\"\\n\ud83d\ude80 Next Steps:\")\n",
    "print(\"  1. Run the dashboard: cap dashboard\")\n",
    "print(\"  2. Create your own metrics with: cap create\")\n",
    "print(\"  3. Remove metrics when done: cap remove\")\n",
    "print(\"  4. Test in the interactive dashboard\")\n",
    "print(\"  5. Deploy to Posit Connect when ready\")\n",
    "\n",
    "print(\"\\n\ud83d\udcda Resources:\")\n",
    "print(\"  \u2022 User Guide: USER_GUIDE.md\")\n",
    "print(\"  \u2022 Architecture: ARCHITECTURE.md\")\n",
    "print(\"  \u2022 Implementation: IMPLEMENTATION_GUIDE.md\")\n",
    "\n",
    "print(\"\\n\ud83d\udd27 Available Commands:\")\n",
    "!cap --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfae Interactive Demo Instructions\n",
    "\n",
    "### \ud83c\udf10 Try the Dashboard (Recommended)\n",
    "\n",
    "1. **Open a terminal** and navigate to this project directory\n",
    "2. **Run the dashboard**: `cap dashboard`\n",
    "3. **Open your browser** to http://localhost:8050\n",
    "4. **Select a metric** from the dropdown menu\n",
    "5. **Enter parameters** in the auto-generated form\n",
    "6. **Click Calculate** to see rich outputs\n",
    "7. **Explore** the interactive charts and tables\n",
    "\n",
    "### \ud83c\udf10 Try the API\n",
    "\n",
    "1. **Open another terminal** and run: `cap api`\n",
    "2. **Visit** http://localhost:8000/docs for interactive API documentation\n",
    "3. **Try different endpoints**:\n",
    "   - GET /metrics (list all metrics)\n",
    "   - POST /calculate (calculate with JSON)\n",
    "   - GET /calculate/{metric_id}/html (rich HTML report)\n",
    "   - GET /calculate/{metric_id}/csv (CSV download)\n",
    "\n",
    "### \ud83d\udee0\ufe0f Create Your Own Metrics\n",
    "\n",
    "1. **Generate new metric**: `cap create \"Your Metric Name\" --template dataframe`\n",
    "2. **Edit the implementation** in `cap/metrics/`\n",
    "3. **Test in dashboard** or with `call_metric()`\n",
    "4. **Remove when done**: `cap remove your_metric_id`\n",
    "5. **Deploy** when ready with the generated deployment script\n",
    "\n",
    "## \ud83c\udd98 Troubleshooting\n",
    "\n",
    "### Quick Verification\n",
    "```bash\n",
    "# Test that everything works\n",
    "python test_installation.py\n",
    "\n",
    "# List available metrics\n",
    "cap list\n",
    "\n",
    "# Create test metric\n",
    "cap create \"Test Metric\" --template simple\n",
    "\n",
    "# Remove test metric\n",
    "cap remove test_metric_id --force\n",
    "```\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "#### **Plotly Charts Not Displaying**\n",
    "```bash\n",
    "# Install Jupyter dependencies for Plotly\n",
    "pip install nbformat>=4.2.0 ipywidgets\n",
    "\n",
    "# Alternative: View charts in dashboard or API HTML endpoints\n",
    "cap dashboard\n",
    "```\n",
    "\n",
    "#### **Other Common Issues**\n",
    "- **Import Errors**: Ensure package installed with `pip install -e \".[all]\"`\n",
    "- **Python Version**: Requires Python 3.11+\n",
    "- **Missing Dependencies**: Install with all features using `[all]` option\n",
    "- **Port Conflicts**: Dashboard uses 8050, API uses 8000\n",
    "\n",
    "### Getting Help\n",
    "- **Documentation**: README.md, USER_GUIDE.md, ARCHITECTURE.md\n",
    "- **Test Script**: Run `python test_installation.py` for diagnostics\n",
    "- **Example Code**: Check `cap/metrics/demo_simple_calculator.py`\n",
    "\n",
    "## \ud83d\udcda Additional Resources\n",
    "\n",
    "### Documentation Files\n",
    "- **\ud83d\udcd6 README.md**: Complete package overview with features\n",
    "- **\ud83d\udc64 USER_GUIDE.md**: Comprehensive user documentation  \n",
    "- **\ud83c\udfd7\ufe0f ARCHITECTURE.md**: Technical architecture and design\n",
    "- **\ud83d\udd27 IMPLEMENTATION_GUIDE.md**: Developer implementation details\n",
    "\n",
    "### Key Commands Reference\n",
    "```bash\n",
    "# Installation and verification\n",
    "pip install -e \".[all]\"\n",
    "pip install nbformat>=4.2.0 ipywidgets  # For Jupyter Plotly support\n",
    "python test_installation.py\n",
    "\n",
    "# CLI commands - simplified syntax\n",
    "cap --help\n",
    "cap list\n",
    "cap create \"Metric Name\" --template dataframe\n",
    "cap remove metric_id\n",
    "cap dashboard\n",
    "cap api\n",
    "\n",
    "# Testing\n",
    "pytest tests/\n",
    "python test_installation.py\n",
    "```\n",
    "\n",
    "### Production Deployment\n",
    "```bash\n",
    "# Test deployment locally\n",
    "python deploy_your_metric.py\n",
    "\n",
    "# Deploy to Posit Connect\n",
    "rsconnect deploy fastapi deploy_your_metric.py \\\n",
    "    --account myaccount \\\n",
    "    --title \"Your Metric API\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83c\udf89 Congratulations!\n",
    "\n",
    "You've completed the **Commercial Analytical Platform (CAP) Demo** and are now ready to:\n",
    "\n",
    "\u2705 **Build sophisticated metrics** with rich outputs (DataFrames, Plotly charts)  \n",
    "\u2705 **Test interactively** using the built-in dashboard  \n",
    "\u2705 **Remove metrics easily** when no longer needed  \n",
    "\u2705 **Deploy to production** with Posit Connect integration  \n",
    "\u2705 **Create scalable analytics** with the scaffolding system  \n",
    "\n",
    "**\ud83d\ude80 Happy metric building with Commercial Analytical Platform (CAP)! \ud83d\ude80**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}